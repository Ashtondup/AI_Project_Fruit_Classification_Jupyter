{"cells":[{"cell_type":"markdown","metadata":{"id":"pWjXNKvVl8MQ"},"source":["# Get data from google drive"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3765,"status":"ok","timestamp":1715854726415,"user":{"displayName":"Bernard Swanepoel","userId":"13499056780325436087"},"user_tz":-120},"id":"9mDvLxQTlQze","outputId":"3e6a20ec-0c05-493a-daea-38bfb113ef72"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"NlsSi9tulAyl"},"source":["# Imports"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1715854726415,"user":{"displayName":"Bernard Swanepoel","userId":"13499056780325436087"},"user_tz":-120},"id":"is_0APkhlAyn"},"outputs":[],"source":["import torch\n","from torchvision import datasets, transforms, utils\n","import torch.nn as nn\n","import torch.optim as optim\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch.nn.functional as F"]},{"cell_type":"markdown","metadata":{"id":"hSNHSPpQlAyp"},"source":["# Check CUDA Availability"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1715854726416,"user":{"displayName":"Bernard Swanepoel","userId":"13499056780325436087"},"user_tz":-120},"id":"BH0XMl3elAyp","outputId":"0906a298-cb90-4577-8c9b-acd2c3aab763"},"outputs":[{"name":"stdout","output_type":"stream","text":["cpu\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"vwzW9EiFlAyq"},"source":["# Dataset Paths"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1715854726416,"user":{"displayName":"Bernard Swanepoel","userId":"13499056780325436087"},"user_tz":-120},"id":"JKWTMl25lAyq","outputId":"47ef23b7-12ca-4ff8-b3ab-f65cdfdc766f"},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n"]}],"source":["fruit_train = '/content/drive/My Drive/notebook_data_and_output/dataset/train'\n","fruit_test = '/content/drive/My Drive/notebook_data_and_output/dataset/test'\n","data_dir = '/content/drive/My Drive/notebook_data_and_output/dataset'\n","print(torch.cuda.device_count())"]},{"cell_type":"markdown","metadata":{"id":"I_KgRy9clAyq"},"source":["# Data Transformations"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1715854726416,"user":{"displayName":"Bernard Swanepoel","userId":"13499056780325436087"},"user_tz":-120},"id":"jkLs5kXhlAyr"},"outputs":[],"source":["data_transform = {\n","    'train': transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.409], [0.229, 0.224, 0.225])\n","    ]),\n","    'test': transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.409], [0.229, 0.224, 0.225])\n","    ])\n","}"]},{"cell_type":"markdown","metadata":{"id":"j5jg3sS0lAyr"},"source":["# Load datasets"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":639,"status":"ok","timestamp":1715854727053,"user":{"displayName":"Bernard Swanepoel","userId":"13499056780325436087"},"user_tz":-120},"id":"ARv_EZhXlAyr"},"outputs":[],"source":["# Load datasets\n","image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transform[x]) for x in ['train', 'test']}"]},{"cell_type":"markdown","metadata":{"id":"89H65doWlAyr"},"source":["# Define class names"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1715854727053,"user":{"displayName":"Bernard Swanepoel","userId":"13499056780325436087"},"user_tz":-120},"id":"7hjzQTiZlAys"},"outputs":[],"source":["class_names = image_datasets['train'].classes"]},{"cell_type":"markdown","metadata":{"id":"oHoQde2ZlAys"},"source":["# Create Data Loaders"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1715854727053,"user":{"displayName":"Bernard Swanepoel","userId":"13499056780325436087"},"user_tz":-120},"id":"vGAKerSqlAys"},"outputs":[],"source":["data_loader = {x: torch.utils.data.DataLoader(image_datasets[x], shuffle=True, batch_size=32, num_workers=0) for x in ['train', 'test']}"]},{"cell_type":"markdown","metadata":{"id":"dBHQ8v-JlAyt"},"source":["# Display sample images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CAnXGi7XlAyt"},"outputs":[],"source":["def imshow(inp, title=None):\n","    inp = inp.numpy().transpose((1, 2, 0))\n","    mean = np.array([0.485, 0.456, 0.406])\n","    std = np.array([0.229, 0.224, 0.225])\n","    inp = std * inp + mean\n","    inp = np.clip(inp, 0, 1)\n","    plt.imshow(inp)\n","    if title is not None:\n","        plt.title(title)\n","    plt.pause(0.001)\n","\n","inputs, classes = next(iter(data_loader['train']))\n","out = utils.make_grid(inputs)\n","imshow(out, title=[class_names[x] for x in classes])"]},{"cell_type":"markdown","metadata":{"id":"Mp2yoyGrlAyt"},"source":["# Define Neural Network Architecture"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lZss4f7ClAyu"},"outputs":[],"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(128)\n","        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n","        self.bn3 = nn.BatchNorm2d(256)\n","        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n","        self.bn4 = nn.BatchNorm2d(512)\n","        self.dropout = nn.Dropout(0.5)\n","        self.fc1 = nn.Linear(512 * 14 * 14, 512)\n","        self.fc2 = nn.Linear(512, 6)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.dropout(F.max_pool2d(self.relu(self.bn1(self.conv1(x))), 2))\n","        x = self.dropout(F.max_pool2d(self.relu(self.bn2(self.conv2(x))), 2))\n","        x = self.dropout(F.max_pool2d(self.relu(self.bn3(self.conv3(x))), 2))\n","        x = self.dropout(F.max_pool2d(self.relu(self.bn4(self.conv4(x))), 2))\n","        x = torch.flatten(x, 1)\n","        x = self.dropout(self.relu(self.fc1(x)))\n","        x = self.fc2(x)\n","        return x\n","\n","net = Net().to(device)  # Move the model to GPU"]},{"cell_type":"markdown","metadata":{"id":"rnldriERlAyu"},"source":["# Load model if it is available"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QKT39FcWlAyu"},"outputs":[],"source":["model_path = '/content/drive/My Drive/notebook_data_and_output/model/fruit_classifier.pth'\n","if os.path.exists(model_path):\n","    net.load_state_dict(torch.load(model_path))\n","    print(\"Loaded saved model.\")\n"]},{"cell_type":"markdown","metadata":{"id":"1XoMFnVrlAyv"},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t6Uru2HmlAyv"},"outputs":[],"source":["# Define the number of EPOCHS\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","\n","EPOCHS = 50\n","patience = 5  # Early stopping patience\n","int i = 0\n","# Initialize optimizer and learning rate scheduler\n","optimizer = optim.Adam(net.parameters(), lr=0.001)\n","cross_el = nn.CrossEntropyLoss()\n","scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.1)\n","\n","best_loss = float('inf')\n","no_improvement_epochs = 0\n","\n","# Training loop\n","for epoch in range(EPOCHS):\n","    print(f\"Epoch: {epoch + 1}\")\n","    net.train()  # Set the model to training mode\n","    running_loss = 0.0  # Initialize running loss for the epoch\n","    \n","    for batch_idx, data in enumerate(data_loader['train']):\n","        x, y = data[0].to(device), data[1].to(device)  # Move data to GPU\n","        optimizer.zero_grad()  # Clear gradients from the previous step\n","        output = net(x)  # Forward pass\n","        loss = cross_el(output, y)  # Compute loss\n","        loss.backward()  # Backpropagation\n","        optimizer.step()  # Update model parameters\n","        \n","        running_loss += loss.item()  # Accumulate loss\n","        i += 1  # Increment step counter\n","        \n","        # Print loss every 100 batches (for example)\n","        if (batch_idx + 1) % 100 == 0:\n","            print(f\"Batch {batch_idx + 1}/{len(data_loader['train'])}, Loss: {loss.item()}\")\n","\n","    # Calculate and print average loss for the epoch\n","    average_loss = running_loss / len(data_loader['train'])\n","    print(f\"Average Loss for Epoch {epoch + 1}: {average_loss}\")\n","\n","    # Check for early stopping\n","    if average_loss < best_loss:\n","        best_loss = average_loss\n","        no_improvement_epochs = 0\n","        # Save the best model\n","        torch.save(net.state_dict(), model_path)\n","        print(f\"Best model saved after epoch {epoch + 1}\")\n","    else:\n","        no_improvement_epochs += 1\n","        print(f\"No improvement for {no_improvement_epochs} epochs\")\n","\n","    # Adjust learning rate based on validation loss\n","    scheduler.step(average_loss)\n","\n","    # Stop training if no improvement for several epochs\n","    if no_improvement_epochs >= patience:\n","        print(\"Early stopping triggered\")\n","        break"]},{"cell_type":"markdown","metadata":{"id":"vuGAiuRtlAyv"},"source":["# Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B2f-PQc5lAyv"},"outputs":[],"source":["k = 0\n","j = 0\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in data_loader['test']:\n","        k += 1\n","        print(\"Test set: \" + str(k))\n","        x, y = data[0].to(device), data[1].to(device)  # Move data to GPU\n","        output = net(x)\n","        for idx, i in enumerate(output):\n","            j += 1\n","            print(j)\n","            if torch.argmax(i) == y[idx]:\n","                correct += 1\n","            total += 1\n","\n","print(f'Accuracy: {round(correct/total, 3)}')"]},{"cell_type":"markdown","metadata":{"id":"Lxj73sF3lAyw"},"source":["# Save model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EuZlH9QQlAyw"},"outputs":[],"source":["torch.save(net.state_dict(), model_path)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}
